{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIDfPaZQ_9yI",
        "outputId": "13994111-fea9-479d-a1ae-ac371bfc7e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/131.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/131.4 kB\u001b[0m \u001b[31m879.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m112.6/131.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-openai \\ faiss-cpu tiktoken python-dotenv langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UugXeNqLFJFF"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQYA5DeqFt2-"
      },
      "source": [
        "## Step 1a - Indexing (Document Ingestion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "amXxIMeGFa6n"
      },
      "outputs": [],
      "source": [
        "video_id = \"3dhcmeOTZ_Q\" # only the ID, not full URL\n",
        "try:\n",
        "    # If you don’t care which language, this returns the “best” one\n",
        "    transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"en\"])\n",
        "\n",
        "    # Flatten it to plain text\n",
        "    transcript = \" \".join(chunk.text for chunk in transcript_list)\n",
        "\n",
        "except TranscriptsDisabled:\n",
        "    print(\"No captions available for this video.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "TYelf9IkHOyu",
        "outputId": "4032b5d2-d175-4fe3-fa29-dd706223559a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[Music] linear regression is a statistical technique for modeling the relationship between an output variable and one or more input variables in layman's terms think of it as fitting a line through some data points as shown here so you can make predictions on unknown data assuming there is a linear relationship between the variables you might be familiar with the linear function y equals mx plus b where y is the output variable also called the dependent variable you may also see expressed as f x the function of the input variable x on the other hand would serve as the input variable also called the independent variable it's likely you'll see the coefficients m and b expressed as beta 1 and beta0 respectively so what do the m and b coefficients do the m or beta 1 coefficient controls the slope of the line the b or the beta 0 controls the intercept of the line in machine learning we also know it as the bias these two coefficients are what we are solving for in linear regression we can also extend multiple input variables so x1 x2 x3 with beta1 beta2 and beta3 and so on acting as slopes for each of those variables in these higher dimensions you would visualize the linear regression as a hyperplane so how do we fit the line to these points well you'll notice that there's these differences between the points and the line these little red segments these are called residuals they are the differences between the data points and the predictions the line would produce take each of these residuals and square them these are the squared errors and notice that the larger the residuals are the more amplified the area of the squares are [Music] if we total the areas of all of these squares for a given line we will get the sum of the squared error and this is known as our loss function we need to find the beta 0 and beta 1 coefficients that will minimize that sum of squared error the coefficients can be solved with a variety of techniques ranging from matrix decomposition to gradient descent which is depicted right here thankfully a lot of libraries are available to do this for us and we will deep dive into these topics in other videos to validate a linear regression there are a number of techniques machine learning practitioners will often take a third of the data and put it into the test data set the remaining two thirds will become the training data set the training data set will then be used to fit the regression line the test data set will then be used to validate the regression line this is done to make sure that the regression performs well on data it has not seen before metrics used to evaluate the linear regression vary from the r square standard error of the estimate prediction intervals as well as statistical significance these are topics we will cover in future videos if you enjoyed this video please like and subscribe look at my two o'reilly books essential math for data science and getting started with sql chapter 5 of essential math for data science actually covers linear regression and much more depth if you want live instruction i also do teach on the o'reilly platform promotional link below i teach classes including machine learning from scratch probability and sql comment on what topics you would like to see next and i will see you again on 3-minute data science [Music]\""
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ9znl3qKGFv"
      },
      "source": [
        "## Step 1b - Indexing (Text Splitting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "AnP_r78tJHDi"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.create_documents([transcript])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFKMjX0hMTfq"
      },
      "source": [
        "## Step 1c & 1d - Indexing (Embedding Generation and Storing in Vector Store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "46p_dYpVLqqg",
        "outputId": "6891b114-6785-4240-cc7e-9310732e03b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3621940441.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embedding=HuggingFaceEmbeddings(),\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LgKB1BAqLuwl",
        "outputId": "c530b648-4863-4500-993c-a88e74316873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '7e4d1d70-ee4d-42ec-a614-77e5297aec47',\n",
              " 1: 'd392421a-212d-414f-9442-c66af4fd27f9',\n",
              " 2: '5b0d9e45-32bb-4a51-a61f-dbac85592441',\n",
              " 3: '3fec63e1-917f-4886-b159-1aaf6e20b071'}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KYIy4WCU3_I"
      },
      "source": [
        "## Step 2 - Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "PpPYzcwaOdxF"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_type = 'similarity', search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnxB9qSIVSDK",
        "outputId": "0149d372-5790-40be-d0c6-8854d0037852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f9bb92c0090>, search_kwargs={'k': 4})"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8suUtsezWEB7"
      },
      "source": [
        "## Step 3 - Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73pU0r93V5kH"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bHCF_T8wWc7B"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ctfgTo23W4lJ"
      },
      "outputs": [],
      "source": [
        "question          = \"what is linear regression\"\n",
        "retrieved_docs    = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yzGF-x8nW86I",
        "outputId": "870c285d-dcec-46c8-84ad-62cffd7188d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='7e4d1d70-ee4d-42ec-a614-77e5297aec47', metadata={}, page_content=\"[Music] linear regression is a statistical technique for modeling the relationship between an output variable and one or more input variables in layman's terms think of it as fitting a line through some data points as shown here so you can make predictions on unknown data assuming there is a linear relationship between the variables you might be familiar with the linear function y equals mx plus b where y is the output variable also called the dependent variable you may also see expressed as f x the function of the input variable x on the other hand would serve as the input variable also called the independent variable it's likely you'll see the coefficients m and b expressed as beta 1 and beta0 respectively so what do the m and b coefficients do the m or beta 1 coefficient controls the slope of the line the b or the beta 0 controls the intercept of the line in machine learning we also know it as the bias these two coefficients are what we are solving for in linear regression we can\"),\n",
              " Document(id='3fec63e1-917f-4886-b159-1aaf6e20b071', metadata={}, page_content=\"set will then be used to fit the regression line the test data set will then be used to validate the regression line this is done to make sure that the regression performs well on data it has not seen before metrics used to evaluate the linear regression vary from the r square standard error of the estimate prediction intervals as well as statistical significance these are topics we will cover in future videos if you enjoyed this video please like and subscribe look at my two o'reilly books essential math for data science and getting started with sql chapter 5 of essential math for data science actually covers linear regression and much more depth if you want live instruction i also do teach on the o'reilly platform promotional link below i teach classes including machine learning from scratch probability and sql comment on what topics you would like to see next and i will see you again on 3-minute data science [Music]\"),\n",
              " Document(id='d392421a-212d-414f-9442-c66af4fd27f9', metadata={}, page_content=\"slope of the line the b or the beta 0 controls the intercept of the line in machine learning we also know it as the bias these two coefficients are what we are solving for in linear regression we can also extend multiple input variables so x1 x2 x3 with beta1 beta2 and beta3 and so on acting as slopes for each of those variables in these higher dimensions you would visualize the linear regression as a hyperplane so how do we fit the line to these points well you'll notice that there's these differences between the points and the line these little red segments these are called residuals they are the differences between the data points and the predictions the line would produce take each of these residuals and square them these are the squared errors and notice that the larger the residuals are the more amplified the area of the squares are [Music] if we total the areas of all of these squares for a given line we will get the sum of the squared error and this is known as our loss\"),\n",
              " Document(id='5b0d9e45-32bb-4a51-a61f-dbac85592441', metadata={}, page_content='are the more amplified the area of the squares are [Music] if we total the areas of all of these squares for a given line we will get the sum of the squared error and this is known as our loss function we need to find the beta 0 and beta 1 coefficients that will minimize that sum of squared error the coefficients can be solved with a variety of techniques ranging from matrix decomposition to gradient descent which is depicted right here thankfully a lot of libraries are available to do this for us and we will deep dive into these topics in other videos to validate a linear regression there are a number of techniques machine learning practitioners will often take a third of the data and put it into the test data set the remaining two thirds will become the training data set the training data set will then be used to fit the regression line the test data set will then be used to validate the regression line this is done to make sure that the regression performs well on data it has not')]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "F0TFAa89X_7E"
      },
      "outputs": [],
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "XpthuUIcoM78",
        "outputId": "aa8d0202-a3db-4acf-9357-92b4e8c16499"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[Music] linear regression is a statistical technique for modeling the relationship between an output variable and one or more input variables in layman's terms think of it as fitting a line through some data points as shown here so you can make predictions on unknown data assuming there is a linear relationship between the variables you might be familiar with the linear function y equals mx plus b where y is the output variable also called the dependent variable you may also see expressed as f x the function of the input variable x on the other hand would serve as the input variable also called the independent variable it's likely you'll see the coefficients m and b expressed as beta 1 and beta0 respectively so what do the m and b coefficients do the m or beta 1 coefficient controls the slope of the line the b or the beta 0 controls the intercept of the line in machine learning we also know it as the bias these two coefficients are what we are solving for in linear regression we can\\n\\nset will then be used to fit the regression line the test data set will then be used to validate the regression line this is done to make sure that the regression performs well on data it has not seen before metrics used to evaluate the linear regression vary from the r square standard error of the estimate prediction intervals as well as statistical significance these are topics we will cover in future videos if you enjoyed this video please like and subscribe look at my two o'reilly books essential math for data science and getting started with sql chapter 5 of essential math for data science actually covers linear regression and much more depth if you want live instruction i also do teach on the o'reilly platform promotional link below i teach classes including machine learning from scratch probability and sql comment on what topics you would like to see next and i will see you again on 3-minute data science [Music]\\n\\nslope of the line the b or the beta 0 controls the intercept of the line in machine learning we also know it as the bias these two coefficients are what we are solving for in linear regression we can also extend multiple input variables so x1 x2 x3 with beta1 beta2 and beta3 and so on acting as slopes for each of those variables in these higher dimensions you would visualize the linear regression as a hyperplane so how do we fit the line to these points well you'll notice that there's these differences between the points and the line these little red segments these are called residuals they are the differences between the data points and the predictions the line would produce take each of these residuals and square them these are the squared errors and notice that the larger the residuals are the more amplified the area of the squares are [Music] if we total the areas of all of these squares for a given line we will get the sum of the squared error and this is known as our loss\\n\\nare the more amplified the area of the squares are [Music] if we total the areas of all of these squares for a given line we will get the sum of the squared error and this is known as our loss function we need to find the beta 0 and beta 1 coefficients that will minimize that sum of squared error the coefficients can be solved with a variety of techniques ranging from matrix decomposition to gradient descent which is depicted right here thankfully a lot of libraries are available to do this for us and we will deep dive into these topics in other videos to validate a linear regression there are a number of techniques machine learning practitioners will often take a third of the data and put it into the test data set the remaining two thirds will become the training data set the training data set will then be used to fit the regression line the test data set will then be used to validate the regression line this is done to make sure that the regression performs well on data it has not\""
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_YND6fN1W-Mj"
      },
      "outputs": [],
      "source": [
        "final_prompt = prompt.invoke({'context':context_text,'question':question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-td-rcCZZxs"
      },
      "source": [
        "## Step 4 - Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "mD4_buPeXlMK"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(final_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OKSPtTNVXuBR",
        "outputId": "58894d81-36bd-47e4-eec0-b88a8ceb92ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Linear regression is a statistical technique for modeling the relationship between an output variable and one or more input variables. It's like fitting a line through some data points to make predictions on unknown data, assuming there is a linear relationship between the variables.\""
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxAnjZn7ahmk"
      },
      "source": [
        "## Building a Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "b0YOTfn8Xu53"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "XqymKIc0aliZ"
      },
      "outputs": [],
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "JQlwnNa_bHef"
      },
      "outputs": [],
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "wR0En0JlcScU"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "EzQ1785bceB1"
      },
      "outputs": [],
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yl0ladnGcl-S",
        "outputId": "4705b5bc-cac5-4e8d-d881-4758ff51785b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In linear regression, we can extend multiple input variables so x1, x2, x3, with beta1, beta2, and beta3, and so on, acting as slopes for each of those variables in these higher dimensions.'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_chain.invoke('explain multiple inputs in linear regression')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-_5OOohc7SB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
